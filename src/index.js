import fs from "fs";
import path from "path";
import chalk from "chalk";
import { getAllRows, pool } from "@anclatechs/sql-buns";
import { generateChecksum } from "./utils/generics.js";
import { loadModels } from "./utils/loadModels.js";
import { diffSchemas } from "./utils/schemaDiffConstructor.js";
import { inspectDBForDrift } from "./utils/integrity.js";
import {
  INITIAL_INSPECTDB_MARKER,
  SUPPORTED_SQL_DIALECTS_TYPES,
} from "./utils/constants.js";
import {
  extractSchemas,
  normalizeSchemasForChecksum,
} from "./utils/extractSchema.js";
const MIGRATIONS_DIR = path.join(process.cwd(), "database/migrations");
const SNAPSHOT_FILE = path.join(MIGRATIONS_DIR, "schema_snapshot.json");

const entryPath = "../";
const pkgPath = path.join(path.dirname(entryPath), "package.json");
const pkg = JSON.parse(fs.readFileSync(pkgPath, "utf-8"));
const sqlBunsMigrateCurrentversion = pkg?.version || "p1";

function sanitizeMigrationName(name) {
  /**
   * 1. Replace special characters with underscore
   * 2. Remove leading/trailing underscores
   */
  return String(name)
    .trim()
    .toLowerCase()
    .replace(/[^a-z0-9_-]+/g, "_")
    .replace(/^_+|_+$/g, "");
}

export async function createMigration(name) {
  // CHECK DIRECTORY
  if (!fs.existsSync(MIGRATIONS_DIR))
    fs.mkdirSync(MIGRATIONS_DIR, { recursive: true });

  const models = await loadModels();
  const currentSchema = extractSchemas(models);

  let oldSchema = {};
  if (fs.existsSync(SNAPSHOT_FILE)) {
    oldSchema = JSON.parse(fs.readFileSync(SNAPSHOT_FILE, "utf-8"));
  }

  const { oldFiltered, currentFiltered } = normalizeSchemasForChecksum(
    oldSchema,
    currentSchema
  );
  const currentChecksum = generateChecksum(currentFiltered);
  const oldChecksum = generateChecksum(oldFiltered);

  if (currentChecksum === oldChecksum) {
    console.log("‚úÖ No schema changes detected.");
    return;
  }

  // Assert that the migration name is not a reserved keyword
  if (sanitizeMigrationName(name).toLowerCase() === INITIAL_INSPECTDB_MARKER) {
    console.error(
      `\n‚ùå Error: The migration name '${INITIAL_INSPECTDB_MARKER}' is reserved.\n` +
        "This name is used internally to detect auto-generated databases.\n" +
        "Please choose a different name.\n"
    );
    process.exit(1);
  }

  // Read all migration files in the directory
  const files = fs
    .readdirSync(MIGRATIONS_DIR)
    .filter((f) => f.endsWith(".sql"))
    .sort();

  // Fetch all migrations already applied to the database
  const applied = await getAllRows(`SELECT name FROM  _sqlbuns_migrations`);
  const appliedNames = new Set(applied.map((r) => r.name));

  // Detect files yet to be applied
  const unapplied = files.filter((f) => !appliedNames.has(f));

  if (unapplied.length > 0) {
    console.error(
      `\n‚ùå Migration files not yet applied:\n${unapplied
        .map((f) => "  - " + f)
        .join("\n")}`
    );
    console.error(
      "\nYour local migration files are out of sync with the database.\nRun: `buns-migrate up` to apply them before creating a new one.\n"
    );
    process.exit(1);
  }

  await inspectDBForDrift(oldSchema, currentSchema);

  const changes = await diffSchemas(oldSchema, currentSchema);

  if (changes.warnings.length > 0) {
    console.log("Warnings:");
    changes.warnings.forEach((w) => console.log(" - " + w));
  }

  const sql = changes.sql.join("\n");
  const reverseSQL = changes.reverseSQL.join("\n");

  const timestamp = Date.now();
  const filename = `${timestamp}_${sanitizeMigrationName(name)}.sql`;
  const reverseSQLFilename = `${timestamp}_${sanitizeMigrationName(name)}.js`;
  const isSQLite =
    process.env.DATABASE_ENGINE === SUPPORTED_SQL_DIALECTS_TYPES.SQLITE;
  fs.writeFileSync(path.join(MIGRATIONS_DIR, filename), sql);
  fs.writeFileSync(
    path.join(MIGRATIONS_DIR, reverseSQLFilename),
    `/*
 * WARNING: This migration file was auto-generated by @anclatechs/sql-buns-migrate
 * on ${new Date().toLocaleDateString("en-US", {
   month: "long",
   day: "numeric",
   year: "numeric",
 })} (version ${sqlBunsMigrateCurrentversion}).
 *
 * Do not edit this file manually, as it may complicate the migration process
 * or lead to unexpected issues. If changes are needed, regenerate the file
 * or modify the source configuration instead. Only proceed with direct edits
 * if you are absolutely certain of the implications.
 */
import { pool } from "@anclatechs/sql-buns";
export async function up() {/**Go to file: ${filename}*/}
export async function down() {
  await pool.${isSQLite ? "run" : "query"}(\`${reverseSQL}\`);
}
  `
  );

  fs.writeFileSync(SNAPSHOT_FILE, JSON.stringify(currentSchema, null, 2));

  console.log(chalk.green(`‚úÖ Migration created: ${filename}`));
}

/**
 * Run all unapplied migrations
 */
export async function migrateUp() {
  console.log(chalk.cyan("üîç Checking for unapplied migrations..."));

  // Get all migration files
  let migrationFiles;
  if (!fs.existsSync(MIGRATIONS_DIR)) {
    migrationFiles = [];
  } else {
    migrationFiles = fs
      .readdirSync(MIGRATIONS_DIR)
      .filter((f) => f.endsWith(".sql"))
      .sort();
  }

  if (migrationFiles.length === 0) {
    console.log(chalk.yellow("‚ö†Ô∏è No migration files found."));
    return;
  }

  // Fetch applied migrations from DB
  const appliedMigrations = await getAllRows(`
        SELECT name, checksum FROM _sqlbuns_migrations
        WHERE direction = 'up' AND rolled_back = false
      `);

  const appliedMap = new Map(
    appliedMigrations.map((m) => [m.name, m.checksum])
  );

  // Filter unapplied migrations
  const unapplied = migrationFiles.filter((file) => !appliedMap.has(file));

  if (unapplied.length === 0) {
    console.log(chalk.green("‚úÖ All migrations are synced up to db."));
    return;
  }

  console.log(chalk.blue(`\nApplying ${unapplied.length} migrations...`));

  for (const file of unapplied) {
    /** CAVEAT -- From my initial process flow, this is designed to only have one unapplied migration
     * at a time, this may be a bottleneck in some instances but the merit is allow us to determine
     * at near 100% accuracy the current schema being processed
     *
     * Thus unapplied array lenght would be === 1
     * */

    let content;
    const dbType = process.env.DATABASE_ENGINE;
    const schema = JSON.parse(fs.readFileSync(SNAPSHOT_FILE, "utf-8"));
    const filePath = path.join(MIGRATIONS_DIR, file);
    if (filePath.includes(INITIAL_INSPECTDB_MARKER)) {
      // Special case: `INITIAL_INSPECTDB_MARKER` migration is a marker file only.
      // It indicates that the database was created via `inspectdb` and should not be re-applied,
      // as doing so would lead to unintended overwrite issues.
      // Its content is intentionally ignored. Some sort of Fake migration pass :check :)
      content = "";
    } else {
      content = fs.readFileSync(filePath, "utf8");
    }
    const checksum = generateChecksum(schema);

    console.log(chalk.cyan(`\n‚ñ∂ Running migration: ${file}`));

    let connection = null;
    const isPostgres = dbType === SUPPORTED_SQL_DIALECTS_TYPES.POSTGRES;
    const isMySQL = dbType === SUPPORTED_SQL_DIALECTS_TYPES.MYSQL;
    const isSQLite = dbType === SUPPORTED_SQL_DIALECTS_TYPES.SQLITE;
    const useConnection = isPostgres || isMySQL;

    try {
      if (isPostgres) {
        connection = await pool.connect();
        await connection.query("BEGIN");
      } else if (isMySQL) {
        connection = await pool.getConnection();
        await connection.beginTransaction();
      } else if (isSQLite) {
        await pool.exec("BEGIN TRANSACTION");
      }

      if (useConnection) {
        await connection.query(content);
      } else {
        await pool.exec(content);
      }

      const params = [file, checksum, "up", false];
      let insertQuery;
      if (isPostgres) {
        insertQuery = `INSERT INTO _sqlbuns_migrations (name, checksum, direction, rolled_back) VALUES ($1, $2, $3, $4)`;
        await connection.query(insertQuery, params);
      } else if (isMySQL) {
        insertQuery = `INSERT INTO _sqlbuns_migrations (name, checksum, direction, rolled_back) VALUES (?, ?, ?, ?)`;
        await connection.query(insertQuery, params);
      } else if (isSQLite) {
        insertQuery = `INSERT INTO _sqlbuns_migrations (name, checksum, direction, rolled_back) VALUES (?, ?, ?, ?)`;
        await pool.run(insertQuery, params);
      }

      // Commit transaction
      if (isPostgres) {
        await connection.query("COMMIT");
      } else if (isMySQL) {
        await connection.commit();
      } else if (isSQLite) {
        await pool.exec("COMMIT");
      }

      console.log(chalk.green(`‚úÖ Migration applied: ${file}`));
    } catch (err) {
      // Rollback on error
      if (isPostgres) {
        if (connection) await connection.query("ROLLBACK");
      } else if (isMySQL) {
        if (connection) await connection.rollback();
      } else if (isSQLite) {
        await pool.exec("ROLLBACK");
      }

      console.error(chalk.red(`‚ùå Failed migration: ${file}`));
      console.error(err.message);
      process.exit(1);
    } finally {
      if (connection) {
        if (isPostgres) {
          connection.release();
        } else if (isMySQL) {
          connection.release();
        }
      }
    }
  }

  console.log(chalk.green("\nüéâ All migrations applied successfully!"));
}

export async function migrateDown() {
  console.log("\nReverting last migration...");

  const dbType = process.env.DATABASE_ENGINE;
  let connection = null;
  const isPostgres = dbType === SUPPORTED_SQL_DIALECTS_TYPES.POSTGRES;
  const isMySQL = dbType === SUPPORTED_SQL_DIALECTS_TYPES.MYSQL;
  const isSQLite = dbType === SUPPORTED_SQL_DIALECTS_TYPES.SQLITE;
  const useConnection = isPostgres || isMySQL;

  if (isPostgres) {
    connection = await pool.connect();
  } else if (isMySQL) {
    connection = await pool.getConnection();
  }

  try {
    // Get latest applied (non-reverted) migration
    const [lastApplied] = await getAllRows(`
      SELECT * FROM _sqlbuns_migrations
      ORDER BY applied_at DESC
      LIMIT 1;
    `);

    if (!lastApplied) {
      console.log("No applied migrations to roll back.");
      return;
    }

    if (lastApplied.rolled_back) {
      console.log(chalk.yellow(`${lastApplied.name} already rolled back.`));
      return;
    }

    const lastFile = lastApplied.name.replace(".sql", ".js");
    const rollbackPath = path.join(MIGRATIONS_DIR, lastFile);

    if (!fs.existsSync(rollbackPath)) {
      console.log(chalk.yellow(`No rollback file found for ${lastFile}`));
      return;
    }

    const rollbackModule = await import(rollbackPath);

    if (!rollbackModule.down) {
      console.log(chalk.yellow(`No 'down' function found in ${lastFile}`));
      return;
    }

    console.log(`\nRunning rollback for ${lastFile}...`);
    await rollbackModule.down(connection || pool);

    // Mark migration as reverted
    if (isPostgres) {
      await connection.query(
        `UPDATE _sqlbuns_migrations 
         SET rolled_back = true, direction = 'down', rolled_back_at = NOW() 
         WHERE id = $1`,
        [lastApplied.id]
      );
    } else if (isMySQL) {
      await connection.query(
        `UPDATE _sqlbuns_migrations 
         SET rolled_back = true, direction = 'down', rolled_back_at = NOW() 
         WHERE id = ?`,
        [lastApplied.id]
      );
    } else if (isSQLite) {
      await pool.run(
        `UPDATE _sqlbuns_migrations 
         SET rolled_back = 1, direction = 'down', rolled_back_at = datetime('now') 
         WHERE id = ?`,
        [lastApplied.id]
      );
    }

    console.log(chalk.green(`‚úÖ Rolled back migration: ${lastFile}`));
  } catch (err) {
    console.error(chalk.red(`‚ùå Rollback failed: ${err.message}`));
  } finally {
    if (useConnection && connection) {
      connection.release();
    }
  }
}

